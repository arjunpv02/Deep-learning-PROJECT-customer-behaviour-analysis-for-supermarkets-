# -*- coding: utf-8 -*-
"""supermarket project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BaXiddoubaq4gcMHG9VgTQZxchIM3iS_
"""

import numpy as np
import pandas as pd
rd = pd.read_csv("/your_dataset4.csv")
#print(rd.head())
print(rd.info())

from google.colab import drive
drive.mount('/content/drive')

import os

file_path = "/content/your_dataset4.csv"
if not os.path.isfile(file_path):
    print("File not found:", file_path)

from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
#print(rd.info())

# Select relevant features
features = rd[['Review ID', 'Product ID', 'Product Name', 'Rating', 'Aspect Sentiment', 'Response', 'Time Spent',
               'Repeatedly Spoken Product', 'Less Checked Item','Purchase Intent',
               'Competition Analysis', 'Recommendations', 'Overall Satisfaction', 'Timespend Looking Ads',
               'Extra Timespend Competitors', 'Item Pickup Competitors', 'Sales Data (2 months)',
               'Brand Rep (2 months)','Foot Traffic Density (in that area)',
               'Packaging Rating']]

# Display the selected features
print(features.head())

#Normalize the selected attributes
scaler = MinMaxScaler()
normalised_features = scaler.fit_transform(features.drop(columns=['Review ID', 'Product ID', 'Product Name']))

#Assign weights to normalised attributes..
# Define the features and their corresponding weights based on priorities
weights = {
    'Rating': 0.1,
    'Aspect Sentiment': 0.1,
    'Response': 0.1,
    'Time Spent': 0.1,
    'Repeatedly Spoken Product': 0.05,
    'Less Checked Item': 0.05,
    'Purchase Intent': 0.05,
    'Competition Analysis': 0.05,
    'Recommendations': 0.05,
    'Overall Satisfaction': 0.05,
    'Timespend Looking Ads': 0.05,
    'Extra Timespend Competitors': 0.05,
    'Item Pickup Competitors': 0.05,
    'Sales Data (2 months)': 0.05,
    'Brand Rep (2 months)': 0.05,
    'Foot Traffic Density (in that area)': 0.05,
    'Packaging Rating': 0.05
}

# Calculate the total weight
total_weight = sum(weights.values())

# Normalize the weights so that their sum is equal to 1
normalized_weights = {feature: weight / total_weight for feature, weight in weights.items()}

# Print the normalized weights for each feature
for feature, weight in normalized_weights.items():
    print(f"{feature}: {weight}")

rd['item value'] = (normalised_features * np.array(list(normalized_weights.values()))).sum(axis=1)

print(rd['item value'])

# prompt: help me to print rd values in descending order

rd.sort_values(by=['item value'], inplace=True, ascending=False)
print(rd)

# prompt: from the above code help me to sort the item values

sorted_products = rd.sort_values(by=['item value'], ascending=False, inplace=True)
print(sorted_products)

from sklearn.model_selection import train_test_split

# Define features and target variable
X = features.drop(columns=['Review ID', 'Product ID', 'Product Name'])  # Features
y = rd['item value']  # Target variable

# Split the data into training and testing sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Display the shapes of the train and test sets
print("X_train shape:", X_train.shape)
print("y_train shape:", y_train.shape)
print("X_test shape:", X_test.shape)
print("y_test shape:", y_test.shape)

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import cross_val_score

# Initialize the Random Forest regressor
rf_regressor = RandomForestRegressor(random_state=42)

# Perform cross-validation (5-fold cross-validation)
scores = cross_val_score(rf_regressor, X_train, y_train, cv=5, scoring='neg_mean_squared_error')

# Convert the scores to positive values and calculate the mean score
rmse_scores = np.sqrt(-scores)
mean_rmse = np.mean(rmse_scores)

print("Mean RMSE (cross-validation):", mean_rmse)

# prompt: as like the above i need to test kn n efficiency too , so give me code

from sklearn.neighbors import KNeighborsRegressor

# Initialize the KNeighborsRegressor
kn_regressor = KNeighborsRegressor(n_neighbors=9)

# Perform cross-validation (5-fold cross-validation)
scores = cross_val_score(kn_regressor, X_train, y_train, cv=5, scoring='neg_mean_squared_error')

# Convert the scores to positive values and calculate the mean score
rmse_scores = np.sqrt(-scores)
mean_rmse = np.mean(rmse_scores)

print("Mean RMSE (KNeighborsRegressor, k=9):", mean_rmse)

# You can repeat the above steps with different values of k to find the optimal k value for your dataset.

# prompt: also do this for 3 more different algorithams, i need to check diiferent algorithms for best fit

# 1. Gradient Boosting Regressor
from sklearn.ensemble import GradientBoostingRegressor

gb_regressor = GradientBoostingRegressor(random_state=42)

# Perform cross-validation (5-fold cross-validation)
scores = cross_val_score(gb_regressor, X_train, y_train, cv=5, scoring='neg_mean_squared_error')

# Convert the scores to positive values and calculate the mean score
rmse_scores = np.sqrt(-scores)
mean_rmse = np.mean(rmse_scores)

print("Mean RMSE (Gradient Boosting Regressor):", mean_rmse)

# 2. Support Vector Regressor
from sklearn.svm import SVR

svr_regressor = SVR(kernel='rbf')

# Perform cross-validation (5-fold cross-validation)
scores = cross_val_score(svr_regressor, X_train, y_train, cv=5, scoring='neg_mean_squared_error')

# Convert the scores to positive values and calculate the mean score
rmse_scores = np.sqrt(-scores)
mean_rmse = np.mean(rmse_scores)

print("Mean RMSE (Support Vector Regressor):", mean_rmse)

# 3. XGBoost Regressor
from xgboost import XGBRegressor

xgb_regressor = XGBRegressor(random_state=42)

# Perform cross-validation (5-fold cross-validation)
scores = cross_val_score(xgb_regressor, X_train, y_train, cv=5, scoring='neg_mean_squared_error')

# Convert the scores to positive values and calculate the mean score
rmse_scores = np.sqrt(-scores)
mean_rmse = np.mean(rmse_scores)

print("Mean RMSE (XGBoost Regressor):", mean_rmse)



# prompt: also check different algorithams too please

# Import necessary libraries
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from sklearn.ensemble import GradientBoostingRegressor
from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error  # Import the required module

# Initialize different regressors
rf_regressor = RandomForestRegressor(random_state=42)
svr_regressor = SVR(kernel='rbf')
gb_regressor = GradientBoostingRegressor(random_state=42)
xgb_regressor = XGBRegressor(random_state=42)

# Define features and target variable
X = features.drop(columns=['Review ID', 'Product ID', 'Product Name'])  # Features
y = rd['item value']  # Target variable

# Split the data into training and testing sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train and evaluate each regressor
models = [
    ('Random Forest', rf_regressor),
    ('Support Vector Regression', svr_regressor),
    ('Gradient Boosting', gb_regressor),
    ('XGBoost', xgb_regressor)
]

for name, model in models:
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    print(f'{name} RMSE: {rmse}')



# prompt: also check liner regression too

from sklearn.linear_model import LinearRegression

# Initialize the Linear Regression model
linear_regression = LinearRegression()

# Train the model
linear_regression.fit(X_train, y_train)

# Evaluate the model
y_pred_linear = linear_regression.predict(X_test)
rmse_linear = np.sqrt(mean_squared_error(y_test, y_pred_linear))

# Print the results
print(f'Linear Regression RMSE: {rmse_linear}')

# prompt: i fixed linear regression model , so categorise these different product using if and elif,,, and find the top top products having high 'item value'

# Categorize products based on 'item value'
def categorize_product(item_value):
    if item_value >= 0.85:
        return "Excellent"
    elif item_value >= 0.74:
        return "Good"
    elif item_value >= 0.55:
        return "Average"
    elif item_value >= 0.2:
        return "Poor"
    else:
        return "Needs Improvement"

# Create a new column with categorized product values
rd['Product Category'] = rd['item value'].apply(categorize_product)

# Find the top N products with the highest 'item value'
top_n = 50
top_products = rd.nlargest(top_n, 'item value')

# Print the top products
print(top_products[['Product Name', 'item value', 'Product Category']])

# prompt: print all the products with necessary features having product category excellent and good in descending 'item  value'

excellent_good_products = rd[rd['Product Category'].isin(['Excellent', 'Good'])]
sorted_excellent_good_products = excellent_good_products.sort_values(by=['item value'], ascending=False)

print(sorted_excellent_good_products[['Product Name', 'Rating', 'Aspect Sentiment', 'Response', 'Time Spent',
               'Repeatedly Spoken Product', 'Less Checked Item','Purchase Intent',
               'Competition Analysis', 'Recommendations', 'Overall Satisfaction', 'Timespend Looking Ads',
               'Extra Timespend Competitors', 'Item Pickup Competitors', 'Sales Data (2 months)',
               'Brand Rep (2 months)','Foot Traffic Density (in that area)',
               'Packaging Rating', 'item value', 'Product Category']])

# prompt: dont need this much features to print , update code in such a way that only print essentail 5 features only

excellent_good_products = rd[rd['Product Category'].isin(['Excellent', 'Good'])]
sorted_excellent_good_products = excellent_good_products.sort_values(by=['item value'], ascending=False)

print(sorted_excellent_good_products[['Product Name', 'Rating', 'Aspect Sentiment', 'Response', 'item value', 'Product Category']])

# prompt: create a piechart of product category

import matplotlib.pyplot as plt

# Extract data for the pie chart
product_category_counts = (
    rd['Product Category'].value_counts()
    .sort_values(ascending=False)
    .head(5)
)
labels = product_category_counts.index.to_list()
sizes = product_category_counts.values.tolist()

# Create the pie chart
fig, ax = plt.subplots()
ax.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)
ax.set_title('Product Category Distribution')
plt.show()





# prompt: in the similar fashion i need to print all the products having poor product category , print it as like above..

poor_products = rd[rd['Product Category'] == 'Poor']
sorted_poor_products = poor_products.sort_values(by=['item value'], ascending=False)

print(sorted_poor_products[['Product Name', 'Rating', 'Aspect Sentiment', 'Response', 'item value', 'Product Category']])

# prompt: give me a frequency diagram  of product category

import matplotlib.pyplot as plt

# Extract data for the frequency diagram
product_category_counts = rd['Product Category'].value_counts()

# Create the frequency diagram
plt.figure(figsize=(12, 6))
product_category_counts.plot(kind='bar')

# Add labels and title
plt.xlabel('Product Category')
plt.ylabel('Frequency')
plt.title('Product Category Frequency Diagram')

# Rotate x-axis labels for better readability
plt.xticks(rotation=45)

# Show the diagram
plt.show()

# prompt: give the top rated products graphs using other visualization tool rather than  matplot lib

import plotly.express as px

# Prepare data for the pie chart
product_category_counts = (
    rd['Product Category'].value_counts()
    .sort_values(ascending=False)
    .head(5)
)
labels = product_category_counts.index.to_list()
sizes = product_category_counts.values.tolist()

# Create the pie chart
fig = px.pie(values=sizes, names=labels, title='Product Category Distribution')
fig.show()

# Prepare data for the frequency diagram
product_category_counts = rd['Product Category'].value_counts()

# Create the frequency diagram
fig = px.bar(product_category_counts, x=product_category_counts.index, y=product_category_counts.values,
             title='Product Category Frequency Diagram')
fig.update_xaxes(tickangle=45)
fig.show()

# Prepare data for the scatter plot
top_rated_products = rd.nlargest(10, 'Rating')

# Create the scatter plot
fig = px.scatter(top_rated_products, x='Product Name', y='Rating',
                 title='Top Rated Products', color='Product Category')
fig.update_layout(xaxis_tickangle=45)
fig.show()

# prompt: get all the top rated products name

top_rated_products = rd.sort_values(by='Rating', ascending=False)
top_rated_product_names = top_rated_products['Product Name'].tolist()
print(top_rated_product_names)

# prompt: give me a complex  diagram of top products

import plotly.graph_objects as go

# Define data
top_products = rd.nlargest(10, 'item value')
product_names = top_products['Product Name'].tolist()
item_values = top_products['item value'].tolist()

# Create the figure
fig = go.Figure(data=[go.Bar(x=product_names, y=item_values, marker_color='lightsalmon')])

# Update layout
fig.update_layout(title='Top Products by Item Value', xaxis_tickangle=45)

# Create a complex diagram
fig.update_layout(
    title='Top Products by Item Value',
    xaxis_tickangle=-45,
    yaxis=dict(
        title='Item Value',
        tickfont=dict(size=14),
        showgrid=True,
        gridwidth=0.5,
        gridcolor='gray'
    ),
    yaxis_showgrid=True,
    yaxis_gridwidth=0.5,
    yaxis_gridcolor='gray',
    plot_bgcolor='white',
    paper_bgcolor='white',
    showlegend=False
)

# Add annotations
for i, value in enumerate(item_values):
    fig.add_annotation(x=i, y=value + 0.05, text=str(value), showarrow=False)

# Display the figure
fig.show()

# prompt: get all the top rated products name and important features and represent  it visyually
import seaborn as sns
# Get the top N products with the highest 'item value'
top_n = 10
top_products = rd.nlargest(top_n, 'item value')

# Select important features
important_features = ['Product Name', 'Rating', 'Aspect Sentiment', 'Response', 'item value', 'Product Category']

# Filter the top products to include only the important features
top_products_filtered = top_products[important_features]

# Create a bar chart to visualize the top products and their important features
plt.figure(figsize=(12, 6))
sns.barplot(x='item value', y='Product Name', hue='Product Category', data=top_products_filtered)

# Add labels and title
plt.xlabel('Item Value')
plt.ylabel('Product Name')
plt.title('Top Products with Important Features')

# Rotate x-axis labels for better readability
plt.xticks(rotation=45)

# Show the diagram
plt.show()
